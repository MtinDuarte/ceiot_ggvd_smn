{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57602088",
   "metadata": {},
   "source": [
    "# Clasificación de datos – SMN\n",
    "\n",
    "En esta sección aplicaremos **métodos de clasificación** utilizando los datos meteorológicos\n",
    "procesados en la **Capa Minería de Datos**, para predecir si **llueve o no llueve** en base a variables como:\n",
    "\n",
    "- Temperatura (`TEMP`)\n",
    "- Humedad (`HUM`)\n",
    "- Presión (`PNM`)\n",
    "- Dirección del viento (`DD`)\n",
    "- Velocidad del viento (`FF`)\n",
    "\n",
    "Se utilizarán tres algoritmos de clasificación:\n",
    "\n",
    "1. Árbol de Decisión\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Regresión Logística\n",
    "\n",
    "Se evaluarán con métricas clásicas:\n",
    "\n",
    "- **Accuracy**\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-Score**\n",
    "\n",
    "Y visualizaremos **matrices de confusión** para interpretar los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b396b85-50af-448d-a4ba-42e441067f6a",
   "metadata": {},
   "source": [
    "# Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54badf77-28f5-43e1-bae3-c299b1068159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importación de librerías completada.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "CLASIFICACION_DIR = Path('../data/clasificacion')\n",
    "CLASIFICACION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Importación de librerías completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3da64f",
   "metadata": {},
   "source": [
    "# Carga de datos y selección de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5328cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOMBRE</th>\n",
       "      <th>FECHA_HORA</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HUM</th>\n",
       "      <th>PNM</th>\n",
       "      <th>DD</th>\n",
       "      <th>FF</th>\n",
       "      <th>estacion_archivo</th>\n",
       "      <th>LLUEVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONCORDIA AERO</td>\n",
       "      <td>2024-06-01 00:00:00</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20240601_concordia_aero</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONCORDIA AERO</td>\n",
       "      <td>2024-06-01 01:00:00</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2</td>\n",
       "      <td>87</td>\n",
       "      <td>1016.2</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>20240601_concordia_aero</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONCORDIA AERO</td>\n",
       "      <td>2024-06-01 02:00:00</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>87</td>\n",
       "      <td>1016.2</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>20240601_concordia_aero</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONCORDIA AERO</td>\n",
       "      <td>2024-06-01 03:00:00</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>20240601_concordia_aero</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONCORDIA AERO</td>\n",
       "      <td>2024-06-01 04:00:00</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>89</td>\n",
       "      <td>1015.4</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>20240601_concordia_aero</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NOMBRE           FECHA_HORA       FECHA  HORA  TEMP  HUM     PNM  \\\n",
       "0  CONCORDIA AERO  2024-06-01 00:00:00  2024-06-01     0  16.0   81  1016.5   \n",
       "1  CONCORDIA AERO  2024-06-01 01:00:00  2024-06-01     1  15.2   87  1016.2   \n",
       "2  CONCORDIA AERO  2024-06-01 02:00:00  2024-06-01     2  15.2   87  1016.2   \n",
       "3  CONCORDIA AERO  2024-06-01 03:00:00  2024-06-01     3  15.0   87  1015.6   \n",
       "4  CONCORDIA AERO  2024-06-01 04:00:00  2024-06-01     4  15.0   89  1015.4   \n",
       "\n",
       "   DD  FF         estacion_archivo  LLUEVE  \n",
       "0  50  20  20240601_concordia_aero       0  \n",
       "1  30  17  20240601_concordia_aero       0  \n",
       "2  30  17  20240601_concordia_aero       0  \n",
       "3  20  17  20240601_concordia_aero       0  \n",
       "4  30  15  20240601_concordia_aero       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cargar el dataset horario\n",
    "df = pd.read_csv(\"../data/mineria/dataset_mineria_horario.csv\")\n",
    "\n",
    "# Variables predictoras y objetivo\n",
    "X = df[['TEMP', 'HUM', 'PNM', 'DD', 'FF']]\n",
    "y = df['LLUEVE']\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb94fcb",
   "metadata": {},
   "source": [
    "# División en conjuntos de entrenamiento y prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08cef93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos de datos:\n",
      "  X_train: (44, 5) -> 44 filas, 5 variables predictoras\n",
      "  X_test : (20, 5) -> 20 filas, 5 variables predictoras\n",
      "  y_train: 44 filas\n",
      "  y_test : 20 filas\n",
      "\n",
      "Distribución de clases en entrenamiento:\n",
      "LLUEVE\n",
      "0    1.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución de clases en prueba:\n",
      "LLUEVE\n",
      "0    1.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Dimensiones de los conjuntos de datos:\")\n",
    "print(f\"  X_train: {X_train.shape} -> {X_train.shape[0]} filas, {X_train.shape[1]} variables predictoras\")\n",
    "print(f\"  X_test : {X_test.shape} -> {X_test.shape[0]} filas, {X_test.shape[1]} variables predictoras\")\n",
    "print(f\"  y_train: {y_train.shape[0]} filas\")\n",
    "print(f\"  y_test : {y_test.shape[0]} filas\")\n",
    "\n",
    "print(\"\\nDistribución de clases en entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución de clases en prueba:\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d0269",
   "metadata": {},
   "source": [
    "# Estandarización de variables\n",
    "Para KNN y regresión logística es importante escalar las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac0d299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Estandarización de variables ===\n",
      "Antes de escalar (primeras 5 filas):\n",
      "    TEMP  HUM     PNM   DD  FF\n",
      "59  19.7   70  1011.8   90   6\n",
      "46  15.1   93  1012.9  360   4\n",
      "0   16.0   81  1016.5   50  20\n",
      "8   14.6   91  1016.1   30  13\n",
      "43  13.7   88  1013.1    0   0\n",
      "\n",
      "Después de escalar (primeras 5 filas):\n",
      "       TEMP       HUM       PNM        DD        FF\n",
      "0  0.451792 -0.695470 -1.285916 -0.504282 -0.665497\n",
      "1 -0.827127  1.137383 -0.548495  1.547387 -1.016178\n",
      "2 -0.576904  0.181112  1.864883 -0.808234  1.789271\n",
      "3 -0.966140  0.978004  1.596730 -0.960209  0.561887\n",
      "4 -1.216363  0.738936 -0.414418 -1.188172 -1.717540\n"
     ]
    }
   ],
   "source": [
    "# Crear y ajustar el escalador\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Mostrar información interpretativa\n",
    "print(\"=== Estandarización de variables ===\")\n",
    "print(\"Antes de escalar (primeras 5 filas):\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nDespués de escalar (primeras 5 filas):\")\n",
    "print(pd.DataFrame(X_train_scaled, columns=X_train.columns).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146387c7",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06870508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Entrenamiento de Modelos de Clasificación ===\n",
      "\n",
      "Modelo Árbol de Decisión entrenado.\n",
      "Profundidad del árbol: 0\n",
      "Número de hojas: 1\n",
      "\n",
      "Modelo KNN entrenado (con datos estandarizados).\n",
      "Número de vecinos usados: 5\n",
      "Forma de los datos entrenados: (44, 5)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Regresión Logística - También requiere estandarización para mejorar la convergencia del algoritmo.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model_log \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel_log\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelo de Regresión Logística entrenado (con datos estandarizados).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoeficientes por variable (impacto en la probabilidad de lluvia):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1335\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1333\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1339\u001b[0m     )\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1342\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)"
     ]
    }
   ],
   "source": [
    "print(\"=== Entrenamiento de Modelos de Clasificación ===\\n\")\n",
    "\n",
    "# Árbol de Decisión - No necesita estandarización porque no depende de la magnitud de las variables.\n",
    "model_tree = DecisionTreeClassifier(random_state=42)\n",
    "model_tree.fit(X_train, y_train)\n",
    "print(\"Modelo Árbol de Decisión entrenado.\")\n",
    "print(f\"Profundidad del árbol: {model_tree.get_depth()}\")\n",
    "print(f\"Número de hojas: {model_tree.get_n_leaves()}\\n\")\n",
    "\n",
    "# K-Nearest Neighbors (KNN) - Necesita variables escaladas para que la distancia euclidiana sea representativa.\n",
    "neighbors = 5\n",
    "model_knn = KNeighborsClassifier(n_neighbors= neighbors)\n",
    "model_knn.fit(X_train_scaled, y_train)\n",
    "print(\"Modelo KNN entrenado (con datos estandarizados).\")\n",
    "print(f\"Número de vecinos usados: {model_knn.n_neighbors}\")\n",
    "print(f\"Forma de los datos entrenados: {model_knn._fit_X.shape}\\n\")\n",
    "\n",
    "# Regresión Logística - También requiere estandarización para mejorar la convergencia del algoritmo.\n",
    "model_log = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_log.fit(X_train_scaled, y_train)\n",
    "print(\"Modelo de Regresión Logística entrenado (con datos estandarizados).\")\n",
    "print(\"Coeficientes por variable (impacto en la probabilidad de lluvia):\")\n",
    "for var, coef in zip(X_train.columns, model_log.coef_[0]):\n",
    "    print(f\"  {var}: {coef:.4f}\")\n",
    "print(f\"Intersección (bias): {model_log.intercept_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9474f7-7317-4c6b-b77c-5c8584d74374",
   "metadata": {},
   "source": [
    "## Interpretación del Entrenamiento de Modelos\n",
    "\n",
    "Luego de entrenar los tres modelos de clasificación, obtenemos información sobre su estructura y parámetros:\n",
    "\n",
    "### Árbol de Decisión\n",
    "- **Profundidad**: Indica cuántas divisiones jerárquicas se realizaron.\n",
    "- **Número de hojas**: Cada hoja representa una **clase final** (llueve / no llueve).\n",
    "\n",
    "En el ejemplo:\n",
    "- Profundidad: `2` → Árbol muy simple, fácil de interpretar.\n",
    "- Hojas: `3` → Tres rutas posibles de decisión.\n",
    "\n",
    "> **Interpretación:**  \n",
    "Un árbol con baja profundidad es más interpretable, pero puede perder precisión si el fenómeno es complejo.  \n",
    "Se busca un equilibrio entre simplicidad y desempeño.\n",
    "\n",
    "---\n",
    "\n",
    "### K-Nearest Neighbors (KNN)\n",
    "- **Número de vecinos usados**: `5`  \n",
    "- **Forma de los datos entrenados**: `(14101, 5)`  \n",
    "\n",
    "Esto significa:\n",
    "- El modelo **almacena todo el conjunto de entrenamiento** para calcular distancias.  \n",
    "- Usa **5 vecinos más cercanos** para decidir si llueve o no.  \n",
    "- Cada fila tiene **5 variables predictoras**: `TEMP`, `HUM`, `PNM`, `DD`, `FF`.\n",
    "\n",
    "> **Interpretación:**  \n",
    "KNN es un modelo **basado en similitud**.  \n",
    "No aprende reglas explícitas, sino que **compara nuevas observaciones** con las ya conocidas.\n",
    "\n",
    "---\n",
    "\n",
    "### Regresión Logística\n",
    "Imprime los **coeficientes de cada variable** y el **intercepto (bias)**.\n",
    "\n",
    "- **Coeficientes**: Indican cómo cambia la **probabilidad de lluvia** según cada variable:  \n",
    "  - Positivo → aumenta la probabilidad de lluvia  \n",
    "  - Negativo → disminuye la probabilidad de lluvia  \n",
    "\n",
    "Ejemplo interpretativo:\n",
    "- `HUM` positivo → mayor humedad favorece la lluvia.\n",
    "- `PNM` negativo → baja presión favorece la lluvia.\n",
    "- `TEMP` negativo → temperaturas altas reducen la probabilidad de lluvia.\n",
    "\n",
    "- **Intercepto (bias)**: `-7.0516`  \n",
    "  - Representa la **tendencia base** del modelo cuando todas las variables están en sus valores promedio (tras la estandarización).  \n",
    "  - Es un **log-odds**, que se puede convertir en probabilidad:  \n",
    "\n",
    "\\[\n",
    "p = \\frac{1}{1 + e^{-(-7.0516)}} \\approx 0.00086\n",
    "\\]\n",
    "\n",
    "Esto significa que **la probabilidad de lluvia base es muy baja**, y solo aumentará si las variables lo justifican (humedad alta y presión baja).\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen\n",
    "- **Árbol de Decisión**: genera reglas explícitas y es interpretable.  \n",
    "- **KNN**: no genera reglas, clasifica por similitud con vecinos cercanos.  \n",
    "- **Regresión Logística**: asigna un **peso** a cada variable y una probabilidad de lluvia.  \n",
    "- El **bias negativo** indica que el modelo, sin señales claras, tiende a predecir **“no llueve”**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c774c",
   "metadata": {},
   "source": [
    "# Evaluación de modelos\n",
    "Se usarán **accuracy, precision, recall y F1-score**, junto con la **matriz de confusión** para visualizar los aciertos y errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar un modelo mostrando métricas y matriz de confusión.\n",
    "def evaluar_modelo(nombre, modelo, X_eval, y_eval):\n",
    "    \n",
    "    y_pred = modelo.predict(X_eval)\n",
    "\n",
    "    # === Métricas ===\n",
    "    acc = accuracy_score(y_eval, y_pred)\n",
    "    prec = precision_score(y_eval, y_pred)\n",
    "    rec = recall_score(y_eval, y_pred)\n",
    "    f1 = f1_score(y_eval, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {nombre} ===\")\n",
    "    print(f\"Accuracy : {acc:.3f} -> Proporción total de aciertos\")\n",
    "    print(f\"Precision: {prec:.3f} -> De los 'llueve' predichos, cuántos fueron correctos\")\n",
    "    print(f\"Recall   : {rec:.3f} -> De las lluvias reales, cuántas detectó el modelo\")\n",
    "    print(f\"F1-Score : {f1:.3f} -> Balance entre Precision y Recall\")\n",
    "\n",
    "    # === Matriz de Confusión ===\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                     xticklabels=[\"No Llueve\",\"Llueve\"], \n",
    "                     yticklabels=[\"No Llueve\",\"Llueve\"])\n",
    "\n",
    "    # Cambiar color de texto según el valor\n",
    "    max_val = cm.max()\n",
    "    for text in ax.texts:\n",
    "        val = int(text.get_text())\n",
    "        # Blanco si valor alto, negro si valor bajo\n",
    "        text.set_color(\"white\" if val > max_val/2 else \"black\")\n",
    "        text.set_size(16)\n",
    "        text.set_weight('bold')\n",
    "\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(f\"Matriz de Confusión - {nombre}\")\n",
    "    plt.show()\n",
    "\n",
    "    return [acc, prec, rec, f1]\n",
    "\n",
    "# Evaluación de los tres modelos\n",
    "resultados = []\n",
    "resultados.append(evaluar_modelo(\"Árbol de Decisión\", model_tree, X_test, y_test))\n",
    "resultados.append(evaluar_modelo(\"KNN\", model_knn, X_test_scaled, y_test))\n",
    "resultados.append(evaluar_modelo(\"Regresión Logística\", model_log, X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b2fbc",
   "metadata": {},
   "source": [
    "## Comparativa de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados, columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\"],\n",
    "                             index=[\"Árbol de Decisión\",\"KNN\",\"Regresión Logística\"])\n",
    "df_resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b14a6",
   "metadata": {},
   "source": [
    "## Cierre de comparativa de métricas\n",
    "\n",
    "- El modelo con mayor **accuracy** indica la mejor capacidad de predicción global.\n",
    "- La **precisión** muestra cuántos de los eventos predichos como lluvia fueron correctos.\n",
    "- El **recall** indica cuántas lluvias reales fueron detectadas.\n",
    "- El **F1-score** balancea precisión y recall, útil si las clases están desbalanceadas.\n",
    "\n",
    "**Interpretación típica:**\n",
    "- Si KNN tiene buen F1-score pero bajo accuracy, es sensible al desbalance.\n",
    "- Si Árbol de Decisión obtiene buen accuracy pero menor recall, puede estar subestimando lluvias.\n",
    "- La elección final depende de priorizar **detectar lluvias** (recall) o **evitar falsas alarmas** (precision).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107793e9-d9b8-4cd0-b99f-b432aa525466",
   "metadata": {},
   "source": [
    "# Guardar el dataset con las predicciones realizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68ca16-6caf-429c-bf8d-a0afd4b3a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar DataFrame con predicciones y probabilidades\n",
    "df_predicciones = df.loc[y_test.index, [\"NOMBRE\",\"FECHA_HORA\",\"LLUEVE\"]].copy()\n",
    "\n",
    "# Predicciones\n",
    "df_predicciones[\"tree_pred\"] = model_tree.predict(X_test)\n",
    "df_predicciones[\"knn_pred\"] = model_knn.predict(X_test_scaled)\n",
    "df_predicciones[\"log_pred\"] = model_log.predict(X_test_scaled)\n",
    "\n",
    "# Probabilidades de lluvia\n",
    "df_predicciones[\"knn_proba\"] = model_knn.predict_proba(X_test_scaled)[:,1]\n",
    "df_predicciones[\"log_proba\"] = model_log.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "# Crear DataFrame de métricas comparativas\n",
    "df_metricas = pd.DataFrame(resultados, \n",
    "                           columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\"],\n",
    "                           index=[\"Árbol de Decisión\",\"KNN\",\"Regresión Logística\"])\n",
    "\n",
    "# Guardar como CSV\n",
    "\n",
    "# Guardar los datasets con las predicciones realizadas. Exportación a CSV\n",
    "df_predicciones.to_csv(CLASIFICACION_DIR / 'clasificacion_predicciones.csv', index=False)\n",
    "print(\"Archivo 'clasificacion_predicciones.csv' generado correctamente.\")\n",
    "\n",
    "# Guardar como CSV\n",
    "df_metricas.to_csv(CLASIFICACION_DIR / 'clasificacion_metricas.csv', index=False)\n",
    "print(\"Archivo 'clasificacion_metricas.csv' generado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6bda5-cf73-4f56-b7ed-3d37a5a571c9",
   "metadata": {},
   "source": [
    "# Visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e980cc7-9cb0-4d8b-b3a8-9801329cb1aa",
   "metadata": {},
   "source": [
    "## Curva ROC y AUC\n",
    "\n",
    "La **Curva ROC (Receiver Operating Characteristic)** muestra la capacidad del modelo para distinguir entre clases.\n",
    "- **Eje X**: Falsos positivos (1 - Especificidad)\n",
    "- **Eje Y**: Verdaderos positivos (Recall o Sensibilidad)\n",
    "- **AUC**: Área bajo la curva; cuanto más cercano a 1, mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7a426-3afd-4488-9aca-a23572c8dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con Regresión Logística\n",
    "y_proba = model_log.predict_proba(X_test_scaled)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC={auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel(\"Tasa de Falsos Positivos (1 - Especificidad)\")\n",
    "plt.ylabel(\"Tasa de Verdaderos Positivos (Recall)\")\n",
    "plt.title(\"Curva ROC - Regresión Logística\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6c2d3-d5b1-488f-9f27-e5b0073fc4bd",
   "metadata": {},
   "source": [
    "## Importancia de Variables (Árbol de Decisión)\n",
    "\n",
    "El **Árbol de Decisión** permite visualizar qué variables tuvieron más influencia para predecir si llueve o no.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d5054-9a97-43e6-a2c7-c88f726d26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = pd.Series(model_tree.feature_importances_, index=X_train.columns)\n",
    "importancia.sort_values().plot(kind='barh', figsize=(6,4), color='skyblue')\n",
    "plt.title(\"Importancia de variables - Árbol de Decisión\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32040821-f73a-438e-8ae9-021c21da0474",
   "metadata": {},
   "source": [
    "## Matriz de Confusión Normalizada\n",
    "\n",
    "La matriz normalizada muestra la proporción de aciertos y errores por clase, facilitando la interpretación cuando hay clases desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f6ad4-a506-485c-85ea-d6edf7b04b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, model_log.predict(X_test_scaled), normalize='true')\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=[\"No Llueve\",\"Llueve\"], yticklabels=[\"No Llueve\",\"Llueve\"])\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión Normalizada - Regresión Logística\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43049597-38bf-4426-b3a9-5a8f09c7c95f",
   "metadata": {},
   "source": [
    "## Distribución de Probabilidades Predichas\n",
    "\n",
    "La distribución de probabilidades permite ver:\n",
    "- Qué tan seguro está el modelo al predecir\n",
    "- Cómo se superponen las clases\n",
    "- Dónde está el umbral de decisión (por defecto 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f7f6e-4f9c-483e-93c5-5af4b48b0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model_log.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_proba[y_test==0], bins=30, alpha=0.6, label='No Llueve')\n",
    "plt.hist(y_proba[y_test==1], bins=30, alpha=0.6, label='Llueve')\n",
    "plt.axvline(0.5, color='red', linestyle='--', label='Umbral 0.5')\n",
    "plt.xlabel(\"Probabilidad predicha de lluvia\")\n",
    "plt.ylabel(\"Cantidad de muestras\")\n",
    "plt.title(\"Distribución de probabilidades predichas - Regresión Logística\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4128c02-45e5-4a11-9413-04cf7d9ee234",
   "metadata": {},
   "source": [
    "## Comparativa de Métricas entre Modelos\n",
    "\n",
    "Permite ver de manera clara cuál modelo tiene mejor:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51210246-85c1-4e37-97cb-e75dc1f59f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame con resultados\n",
    "df_resultados = pd.DataFrame(resultados, \n",
    "                             columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\"],\n",
    "                             index=[\"Árbol de Decisión\",\"KNN\",\"Regresión Logística\"])\n",
    "\n",
    "# Crear gráfico de barras con Blues y bordes\n",
    "ax = df_resultados.plot(\n",
    "    kind='bar', figsize=(9,5), rot=0, \n",
    "    colormap='Blues', edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title(\"Comparativa de métricas por modelo\", fontsize=14)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Etiquetas dentro de las barras: blancas solo para F1-Score\n",
    "for i, container in enumerate(ax.containers):\n",
    "    # i=0 Accuracy, i=1 Precision, i=2 Recall, i=3 F1-Score\n",
    "    color_text = 'white' if i == 3 else 'black'\n",
    "    ax.bar_label(container, fmt='%.2f', label_type='center', fontsize=8, color=color_text, weight='bold')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d4628-984b-48de-8a79-587a3b20b887",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "En esta etapa se trabajó sobre el **dataset final proveniente de la etapa de minería de datos**, donde la información ya había sido procesada y contenía la variable binaria `LLUEVE` como objetivo de clasificación.  \n",
    "El objetivo principal fue **aplicar métodos de clasificación supervisada** para predecir la ocurrencia de lluvia a partir de datos meteorológicos horarios.\n",
    "\n",
    "Se realizaron los siguientes pasos clave:\n",
    "\n",
    "1. **Selección de variables relevantes** (`TEMP`, `HUM`, `PNM`, `DD`, `FF`) como insumos para los modelos de clasificación.  \n",
    "2. **Estandarización de los datos** para algoritmos sensibles a la escala, como KNN y Regresión Logística.  \n",
    "3. **División del dataset en conjuntos de entrenamiento y prueba** para evaluar objetivamente el desempeño de los modelos.  \n",
    "4. **Entrenamiento y evaluación de modelos supervisados** (Árbol de Decisión, KNN y Regresión Logística) utilizando métricas como Accuracy, Precision, Recall y F1-Score.  \n",
    "5. **Visualizaciones complementarias** como matrices de confusión, curvas ROC, histogramas de probabilidades y análisis de importancia de variables, que permitieron interpretar los resultados y validar el desempeño de cada modelo.\n",
    "\n",
    "Este proceso consolida la etapa de **clasificación supervisada**, transformando los datos procesados en **conocimiento accionable**, y dejando una base sólida para **predicciones futuras, integración en pipelines analíticos y toma de decisiones basadas en datos**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0482b-c509-4314-a3ed-e4fd8276c3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
