{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Clase 3 – Ingesta y Capa Bronce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a3d2d",
   "metadata": {},
   "source": [
    "En esta notebook se inicia la construcción del pipeline de datos meteorológicos, trabajando con los archivos crudos provistos por el SMN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## 1. Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "573fb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## 2. Configuración de paths y carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "069e436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "for path in [BRONCE_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## 3. Lectura del archivo de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3fd630d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones cargadas: 117\n",
      "Cantidad de provincias: 25\n",
      "Provincias disponibles: ['ANTARTIDA' 'BUENOS AIRES' 'CAPITAL FEDERAL' 'CATAMARCA' 'CHACO' 'CHUBUT'\n",
      " 'CORDOBA' 'CORRIENTES' 'ENTRE RIOS' 'FORMOSA' 'JUJUY' 'LA PAMPA'\n",
      " 'LA RIOJA' 'MENDOZA' 'MISIONES' 'NEUQUEN' 'RIO NEGRO' 'SALTA' 'SAN JUAN'\n",
      " 'SAN LUIS' 'SANTA CRUZ' 'SANTA FE' 'SANTIAGO DEL ESTERO'\n",
      " 'TIERRA DEL FUEGO' 'TUCUMAN']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>provincia</th>\n",
       "      <th>numero</th>\n",
       "      <th>numero_oaci</th>\n",
       "      <th>coordenadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CONCORDIA AERO</td>\n",
       "      <td>ENTRE RIOS</td>\n",
       "      <td>87395</td>\n",
       "      <td>SAAC</td>\n",
       "      <td>(-31.18 , -58.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GUALEGUAYCHU AERO</td>\n",
       "      <td>ENTRE RIOS</td>\n",
       "      <td>87497</td>\n",
       "      <td>SAAG</td>\n",
       "      <td>(-33.00 , -58.36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PARANA AERO</td>\n",
       "      <td>ENTRE RIOS</td>\n",
       "      <td>87374</td>\n",
       "      <td>SAAP</td>\n",
       "      <td>(-31.47 , -60.29)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nombre   provincia  numero numero_oaci        coordenadas\n",
       "57     CONCORDIA AERO  ENTRE RIOS   87395        SAAC  (-31.18 , -58.00)\n",
       "58  GUALEGUAYCHU AERO  ENTRE RIOS   87497        SAAG  (-33.00 , -58.36)\n",
       "59        PARANA AERO  ENTRE RIOS   87374        SAAP  (-31.47 , -60.29)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta del archivo\n",
    "archivo_estaciones = RAW_DIR / 'estaciones' / 'estaciones_smn.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_estaciones, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()[2:]\n",
    "\n",
    "# Expresión regular para extraer campos:\n",
    "pattern = re.compile(\n",
    "    r\"^(?P<nombre>.+?)\\s{2,}(?P<provincia>.+?)\\s{2,}(?P<lat_gr>-?\\d+)\\s+(?P<lat_min>\\d+)\\s+(?P<lon_gr>-?\\d+)\\s+(?P<lon_min>\\d+)\\s+(?P<altura_m>\\d+)\\s+(?P<numero>\\d+)\\s+(?P<numero_oaci>\\S+)\\s*$\"\n",
    ")\n",
    "\n",
    "# Extraer los datos\n",
    "data = []\n",
    "for line in lines:\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        data.append(match.groupdict())\n",
    "\n",
    "# Crear DataFrame\n",
    "df_estaciones = pd.DataFrame(data)\n",
    "\n",
    "# Conversión de tipos\n",
    "df_estaciones[['lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero']] = df_estaciones[[\n",
    "    'lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero'\n",
    "]].apply(pd.to_numeric)\n",
    "\n",
    "print(\"Estaciones cargadas:\", len(df_estaciones))\n",
    "\n",
    "provincias_unicas = df_estaciones['provincia'].dropna().str.strip().loc[lambda s: s != ''].str.upper().unique()\n",
    "\n",
    "print(\"Cantidad de provincias:\", len(provincias_unicas))\n",
    "\n",
    "print(\"Provincias disponibles:\", provincias_unicas)\n",
    "\n",
    "# Filtrar estaciones de Entre Ríos (.copy va porque evita un warning)\n",
    "df_ERios = df_estaciones[df_estaciones['provincia'].str.upper().str.strip() == 'ENTRE RIOS'].copy()\n",
    "\n",
    "# Crear columna coordenadas\n",
    "df_ERios['coordenadas'] = df_ERios.apply(\n",
    "    lambda r: f\"({int(r['lat_gr'])}.{int(r['lat_min']):02d} , {int(r['lon_gr'])}.{int(r['lon_min']):02d})\",\n",
    "    axis=1\n",
    ")\n",
    "df_ERios[['nombre', 'provincia', 'numero', 'numero_oaci','coordenadas']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Selección de estaciones de Entre Ríos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30913a99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0fa485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>provincia</th>\n",
       "      <th>numero</th>\n",
       "      <th>numero_oaci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CONCORDIA AERO</td>\n",
       "      <td>ENTRE RIOS</td>\n",
       "      <td>87395</td>\n",
       "      <td>SAAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GUALEGUAYCHU AERO</td>\n",
       "      <td>ENTRE RIOS</td>\n",
       "      <td>87497</td>\n",
       "      <td>SAAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PARANA AERO</td>\n",
       "      <td>ENTRE RIOS</td>\n",
       "      <td>87374</td>\n",
       "      <td>SAAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nombre   provincia  numero numero_oaci\n",
       "57     CONCORDIA AERO  ENTRE RIOS   87395        SAAC\n",
       "58  GUALEGUAYCHU AERO  ENTRE RIOS   87497        SAAG\n",
       "59        PARANA AERO  ENTRE RIOS   87374        SAAP"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ERios = df_estaciones[df_estaciones['provincia'].str.upper() == 'ENTRE RIOS']\n",
    "df_ERios[['nombre', 'provincia', 'numero', 'numero_oaci']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545f8b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Lectura de un archivo horario de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c3af388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[HOA]  [ºC]   [%]  [hPa]  [gr] [km/hr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01062024     0  14.2   82  1015.7   50   17     AEROPARQUE AERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01062024     1  14.3   80  1015.4  360    9     AEROPARQUE AERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01062024     2  14.1   86  1015.3  360    9     AEROPARQUE AERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01062024     3  14.1   87  1014.8  360    7     AEROPARQUE AERO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE                                             \n",
       "0           [HOA]  [ºC]   [%]  [hPa]  [gr] [km/hr]                                                     \n",
       "1  01062024     0  14.2   82  1015.7   50   17     AEROPARQUE AERO                                     \n",
       "2  01062024     1  14.3   80  1015.4  360    9     AEROPARQUE AERO                                     \n",
       "3  01062024     2  14.1   86  1015.3  360    9     AEROPARQUE AERO                                     \n",
       "4  01062024     3  14.1   87  1014.8  360    7     AEROPARQUE AERO                                     "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivo_dato = RAW_DIR / 'datohorario' / 'datohorario20240601.txt'\n",
    "\n",
    "df_dato = pd.read_csv(archivo_dato, sep=';', encoding='latin1')\n",
    "\n",
    "df_dato.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425531c",
   "metadata": {},
   "source": [
    "## 6. Limpieza básica y detección de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36cc4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reemplazados 0 valores de 9999.9 y 0 valores de -9999 por NaN.\n",
      "Valores faltantes por columna luego del reemplazo:\n",
      "FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE                                                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar valores a reemplazar antes de la limpieza\n",
    "cant_9999_9 = (df_dato == 9999.9).sum().sum()\n",
    "cant_neg9999 = (df_dato == -9999).sum().sum()\n",
    "\n",
    "# Reemplazar por NaN\n",
    "df_dato.replace({9999.9: np.nan, -9999: np.nan}, inplace=True)\n",
    "\n",
    "# Imprimir resumen\n",
    "print(f\"Reemplazados {cant_9999_9} valores de 9999.9 y {cant_neg9999} valores de -9999 por NaN.\")\n",
    "print(\"Valores faltantes por columna luego del reemplazo:\")\n",
    "print(df_dato.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03c2ef",
   "metadata": {},
   "source": [
    "## 7. Filtro por estación de Entre Ríos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d97ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FECHA HORA TEMP HUM    PNM  DD FF            NOMBRE\n",
      "01062024    0 16.0  81 1016.5  50 20    CONCORDIA AERO\n",
      "01062024    1 15.2  87 1016.2  30 17    CONCORDIA AERO\n",
      "01062024    2 15.2  87 1016.2  30 17    CONCORDIA AERO\n",
      "01062024    3 15.0  87 1015.6  20 17    CONCORDIA AERO\n",
      "01062024    4 15.0  89 1015.4  30 15    CONCORDIA AERO\n",
      "01062024    5 15.0  91 1015.3  90  4    CONCORDIA AERO\n",
      "01062024    6 14.8  93 1015.3  50 11    CONCORDIA AERO\n",
      "01062024    7 14.6  91 1015.7  50  9    CONCORDIA AERO\n",
      "01062024    8 14.6  91 1016.1  30 13    CONCORDIA AERO\n",
      "01062024    9 15.3  87 1016.4  30  9    CONCORDIA AERO\n",
      "01062024   10 16.4  85 1016.4  30 15    CONCORDIA AERO\n",
      "01062024   11 17.6  80 1016.4  20 11    CONCORDIA AERO\n",
      "01062024   12 19.2  72 1016.0  30 19    CONCORDIA AERO\n",
      "01062024   13 20.2  70 1014.9  20 19    CONCORDIA AERO\n",
      "01062024   14 21.4  67 1014.0 360 13    CONCORDIA AERO\n",
      "01062024   15 22.4  66 1013.4  20 15    CONCORDIA AERO\n",
      "01062024   16 22.1  67 1013.3  30 13    CONCORDIA AERO\n",
      "01062024   17 21.2  75 1013.3  90  4    CONCORDIA AERO\n",
      "01062024   18 19.5  81 1013.6  30  7    CONCORDIA AERO\n",
      "01062024   19 18.4  88 1013.6  60  4    CONCORDIA AERO\n",
      "01062024   20 17.8  88 1014.0  30  7    CONCORDIA AERO\n",
      "01062024   21 17.6  89 1014.3  30  9    CONCORDIA AERO\n",
      "01062024   22 17.2  89 1014.3  30  9    CONCORDIA AERO\n",
      "01062024   23 17.8  85 1013.9  20 11    CONCORDIA AERO\n",
      "01062024    6 14.0  94 1013.8  90  7 GUALEGUAYCHU AERO\n",
      "01062024    7 14.3  92 1014.5  70  6 GUALEGUAYCHU AERO\n",
      "01062024    8 14.7  89 1014.7  70  6 GUALEGUAYCHU AERO\n",
      "01062024    9 14.8  89 1014.9  50  7 GUALEGUAYCHU AERO\n",
      "01062024   10 15.7  90 1014.9  20 13 GUALEGUAYCHU AERO\n",
      "01062024   11 17.5  80 1014.6 360 13 GUALEGUAYCHU AERO\n",
      "01062024   12 20.4  73 1013.9 320 11 GUALEGUAYCHU AERO\n",
      "01062024   13 22.5  66 1013.0 320 19 GUALEGUAYCHU AERO\n",
      "01062024   14 23.1  63 1012.4 270 24 GUALEGUAYCHU AERO\n",
      "01062024   15 24.2  58 1011.9 230 19 GUALEGUAYCHU AERO\n",
      "01062024   16 24.7  56 1011.6 230 13 GUALEGUAYCHU AERO\n",
      "01062024   17 23.2  60 1012.0 230  9 GUALEGUAYCHU AERO\n",
      "01062024   18 20.6  72 1012.3 200  7 GUALEGUAYCHU AERO\n",
      "01062024   19 19.7  76 1012.8 180  4 GUALEGUAYCHU AERO\n",
      "01062024   20 16.2  86 1013.2 160  4 GUALEGUAYCHU AERO\n",
      "01062024   21 16.0  87 1012.8 140  6 GUALEGUAYCHU AERO\n",
      "01062024    0 15.4  82 1014.3 360 11       PARANA AERO\n",
      "01062024    1 14.3  86 1013.8 360  7       PARANA AERO\n",
      "01062024    2 14.4  86 1013.7 140  4       PARANA AERO\n",
      "01062024    3 13.7  88 1013.1   0  0       PARANA AERO\n",
      "01062024    4 13.7  90 1013.1  70  4       PARANA AERO\n",
      "01062024    5 13.2  92 1012.9  90  6       PARANA AERO\n",
      "01062024    6 15.1  93 1012.9 360  4       PARANA AERO\n",
      "01062024    7 14.6  93 1013.4  70  2       PARANA AERO\n",
      "01062024    8 14.1  93 1014.2 140  4       PARANA AERO\n",
      "01062024    9 13.6  97 1014.8 140  4       PARANA AERO\n",
      "01062024   10 14.7  94 1014.7  20  4       PARANA AERO\n",
      "01062024   11 18.2  83 1014.3 340 17       PARANA AERO\n",
      "01062024   12 20.2  71 1014.2 320 13       PARANA AERO\n",
      "01062024   13 21.3  67 1013.3 320 13       PARANA AERO\n",
      "01062024   14 22.3  60 1012.2 320 15       PARANA AERO\n",
      "01062024   15 23.2  59 1011.2 320 13       PARANA AERO\n",
      "01062024   16 23.7  57 1011.6 320  9       PARANA AERO\n",
      "01062024   17 23.6  57 1011.6 340  6       PARANA AERO\n",
      "01062024   18 21.5  62 1011.7  50  7       PARANA AERO\n",
      "01062024   19 19.7  70 1011.8  90  6       PARANA AERO\n",
      "01062024   20 18.0  82 1012.0 360  4       PARANA AERO\n",
      "01062024   21 17.5  86 1012.4 330  6       PARANA AERO\n",
      "01062024   22 16.5  90 1012.5 360  4       PARANA AERO\n",
      "01062024   23 15.1  93 1012.4 120  4       PARANA AERO\n"
     ]
    }
   ],
   "source": [
    "archivo_dato = RAW_DIR / 'datohorario' / 'datohorario20240601.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_dato, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Detectar columnas separadas por múltiples espacios\n",
    "columnas = re.split(r\"\\s{2,}\", lines[0].strip())\n",
    "\n",
    "# Leer datos\n",
    "data = [\n",
    "    re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "    for line in lines[1:]\n",
    "    if len(line.strip()) > 0 and not line.isspace()\n",
    "]\n",
    "\n",
    "df_dato = pd.DataFrame(data, columns=columnas)\n",
    "\n",
    "# Filtrar por estaciones de Entre Ríos\n",
    "df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "\n",
    "df_nombresEstaciones = df_ERios[\"nombre\"].str.strip().unique()\n",
    "\n",
    "df_ERios_dia = df_dato[df_dato[\"NOMBRE\"].isin(df_nombresEstaciones)]\n",
    "\n",
    "# Mostrar todos los resultados (sin limitar con .head())\n",
    "print(df_ERios_dia.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63370d18",
   "metadata": {},
   "source": [
    "## 8. Exportación de archivos filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f344ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado: 20240601_concordia_aero.csv y 20240601_concordia_aero.parquet\n",
      "Exportado: 20240601_gualeguaychu_aero.csv y 20240601_gualeguaychu_aero.parquet\n",
      "Exportado: 20240601_parana_aero.csv y 20240601_parana_aero.parquet\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta de salida si no existe\n",
    "BRONCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Definir la fecha (puede venir del nombre del archivo)\n",
    "fecha = \"20240601\"  # o extraela dinámicamente si lo preferís\n",
    "\n",
    "# Iterar por cada estación de Misiones\n",
    "for estacion in df_nombresEstaciones:\n",
    "    nombre_clean = estacion.lower().replace(' ', '_')\n",
    "    \n",
    "    # Filtrar las filas de esa estación\n",
    "    df_estacion = df_ERios_dia[df_ERios_dia[\"NOMBRE\"] == estacion]\n",
    "    \n",
    "    # Definir archivos de salida con fecha al inicio\n",
    "    salida_csv = BRONCE_DIR / f'{fecha}_{nombre_clean}.csv'\n",
    "    salida_parquet = BRONCE_DIR / f'{fecha}_{nombre_clean}.parquet'\n",
    "    \n",
    "    # Exportar\n",
    "    df_estacion.to_csv(salida_csv, index=False)\n",
    "    df_estacion.to_parquet(salida_parquet, index=False)\n",
    "    \n",
    "    print(f\"Exportado: {salida_csv.name} y {salida_parquet.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53b561",
   "metadata": {},
   "source": [
    "## 9. Próximos pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7c349",
   "metadata": {},
   "source": [
    "- Extender este proceso a más días o meses.\n",
    "- Organizar las salidas por carpeta `/bronce/{estacion}/{año}/`.\n",
    "- Documentar el diccionario de variables en `metadata/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2c2bbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Proceso completado.\n",
      "Días procesados: 391\n",
      "Errores al procesar archivos: 391\n",
      "Valores reemplazados: 0 de 9999.9 y 0 de -9999\n",
      "Total de valores nulos luego de limpieza: 260790\n"
     ]
    }
   ],
   "source": [
    "# Por cada archivo, cargar datos y filtrar por las estaciones de Entre Ríos\n",
    "from glob import glob\n",
    "\n",
    "errores_globales = 0\n",
    "nulos_total = 0\n",
    "reemplazados_9999_9 = 0\n",
    "reemplazados_neg9999 = 0\n",
    "detalle_nulos = []\n",
    "\n",
    "# Buscar todos los archivos datohorario disponibles\n",
    "archivos_datos = sorted(glob(str(RAW_DIR / 'datohorario' / \"datohorario*.txt\")))\n",
    "\n",
    "for archivo in archivos_datos:\n",
    "    try:\n",
    "        # Leer el archivo como texto plano\n",
    "        with open(archivo, encoding=\"latin1\") as f:\n",
    "            raw_lines = f.readlines()\n",
    "\n",
    "        # Obtener nombre de columnas desde la primera línea\n",
    "        header = raw_lines[0].strip()\n",
    "        columnas = re.split(r\"\\s{2,}\", header)\n",
    "\n",
    "        # Procesar líneas de datos\n",
    "        data = [re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "                for line in raw_lines[1:] if len(line.strip()) > 0 and not line.isspace()]\n",
    "\n",
    "        # Crear DataFrame\n",
    "        df_dato = pd.DataFrame(data, columns=columnas)\n",
    "        df_dato.columns = df_dato.columns.str.strip()\n",
    "        df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "        \n",
    "        # Convertir columnas numéricas si es posible\n",
    "        for col in df_dato.columns:\n",
    "            try:\n",
    "                df_dato[col] = pd.to_numeric(df_dato[col])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Reemplazo\n",
    "        df_dato.replace({9999.9: np.nan, -9999: np.nan}, inplace=True)\n",
    "\n",
    "        # Contar nulos\n",
    "        nulos_total += df_dato.isna().sum().sum()\n",
    "\n",
    "        # Filtrar por estaciones de EntreRios\n",
    "        df_dato_eRios = df_dato[df_dato[\"NOMBRE\"].str.strip().isin(df_nombresEstaciones)]\n",
    "\n",
    "        # Obtener fecha\n",
    "        fecha = Path(archivo).stem.replace(\"datohorario\", \"\")\n",
    "\n",
    "                # Guardar archivos por estación + generar detalle\n",
    "        for nombre in df_nombresEstaciones:\n",
    "            nombre_clean = nombre.lower().replace(\" \", \"_\")\n",
    "            df_estacion = df_misiones[df_misiones[\"NOMBRE\"] == nombre]\n",
    "\n",
    "            if not df_estacion.empty:\n",
    "                path_estacion = BRONCE_DIR / nombre_clean\n",
    "                path_estacion.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                df_estacion.to_parquet(path_estacion / f\"{fecha}.parquet\", index=False)\n",
    "                df_estacion.to_csv(path_estacion / f\"{fecha}.csv\", index=False)\n",
    "\n",
    "                # Registro de nulos por estación\n",
    "                nulos_por_col = df_estacion.isna().sum()\n",
    "                detalle_nulos.append({\n",
    "                    \"archivo\": Path(archivo).name,\n",
    "                    \"fecha\": fecha,\n",
    "                    \"estacion\": nombre,\n",
    "                    \"nulos_totales\": int(nulos_por_col.sum()),\n",
    "                    \"nulos_por_columna\": json.dumps(nulos_por_col[nulos_por_col > 0].to_dict())\n",
    "                })\n",
    "    except Exception as e:\n",
    "        errores_globales += 1\n",
    "        continue\n",
    "    \n",
    "    \n",
    "# Reporte final\n",
    "print(\"✅ Proceso completado.\")\n",
    "print(f\"Días procesados: {len(archivos_datos)}\")\n",
    "print(f\"Errores al procesar archivos: {errores_globales}\")\n",
    "print(f\"Valores reemplazados: {reemplazados_9999_9} de 9999.9 y {reemplazados_neg9999} de -9999\")\n",
    "print(f\"Total de valores nulos luego de limpieza: {nulos_total}\")\n",
    "\n",
    "# Guardar resumen general\n",
    "reporte = {\n",
    "    \"dias_procesados\": [len(archivos_datos)],\n",
    "    \"errores\": [errores_globales],\n",
    "    \"reemplazados_9999_9\": [reemplazados_9999_9],\n",
    "    \"reemplazados_-9999\": [reemplazados_neg9999],\n",
    "    \"valores_nulos_totales\": [nulos_total],\n",
    "}\n",
    "df_reporte = pd.DataFrame(reporte)\n",
    "df_reporte.to_csv(BRONCE_DIR / \"reporte_resumen.csv\", index=False)\n",
    "\n",
    "# Guardar detalle de nulos por archivo y estación\n",
    "df_detalle = pd.DataFrame(detalle_nulos)\n",
    "df_detalle.to_csv(BRONCE_DIR / \"reporte_nulos_detalle.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97415712-1be9-4f69-888f-db2814718795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7cb9c-a97c-4d1a-a507-716c7e73468b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
